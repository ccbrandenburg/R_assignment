---
title: "R Assignment"
output: html_document
---
Questions we might want to answer, just add below:

Is there a relationship between topic and shares?
If so what is the best performing topic?

Weekday vs weekends
-which topics perform best when?

Best performing article?


Loading libraries
```{r library}
library(ggplot2)
library(dplyr)
```

Loading and examining the data
```{r load data and examine}
data=read.csv("OnlineNewsPopularity.csv", stringsAsFactors = FALSE)
glimpse(data)
dim(data)
tbl_df(data)
head(data)


#PCA
log.data = log
```

Summary

Reducing Data:
1. __filter__    : To select some rows of the dataset
2. __select__    : To select columns
3. __arrange__   : To sort observations
4. __mutate__    : To modify the structure of the dataset (add variables, etc.)
5. __summarize__ : Together with group_by(), used to reduce variables to values

```{r reduction}
#reducing the dataset to relevent variables
#feel free to add any. I would say we try to have our code mainly refer to the below dataset, fine?
data_s = data %>%
  select(url,
         num_keywords,
         n_tokens_title,
         num_imgs,
         num_videos,
         n_tokens_content, 
         weekday_is_monday, 
         weekday_is_tuesday, 
         weekday_is_wednesday,
         weekday_is_thursday, 
         weekday_is_friday,
         weekday_is_saturday,
         weekday_is_sunday,
         is_weekend,
         rate_positive_words,
         rate_negative_words,
         title_sentiment_polarity,
         data_channel_is_lifestyle,
         data_channel_is_socmed,
         data_channel_is_tech,
         data_channel_is_world,
         data_channel_is_entertainment,
         data_channel_is_bus,
         title_subjectivity,
         title_sentiment_polarity,
         abs_title_subjectivity,
         abs_title_sentiment_polarity,
         average_token_length,
         shares)
```

First exploration
```{r}
qplot(data=data_s,
      n_tokens_title,
      geom="histogram")

qplot(data=data_s,
      rate_positive_words,
      shares,
      log="xy")

cor(data_s$rate_positive_words, data_s$shares)
  
qplot(data=data_s,
      title_sentiment_polarity,
      geom="histogram")   

qplot(data=data_s,
      title_sentiment_polarity,
      shares)

summary(data_s$shares)

```

Mutating variables
```{r mutate weekday and weekend variables}
library(dplyr)
data_s = data_s %>%
  #create weekday variable 
  mutate(weekday = ifelse(weekday_is_monday==1, 1,
                    ifelse(weekday_is_tuesday==1, 2,
                    ifelse(weekday_is_wednesday==1, 3,
                    ifelse(weekday_is_thursday==1, 4,
                    ifelse(weekday_is_friday==1, 5,
                    ifelse(weekday_is_saturday==1, 6,
                    ifelse(weekday_is_sunday==1, 7,0)))))))) %>%
  mutate(weekday_flag = ifelse(weekday<=5, 1, 0)) %>%
  #create channel variable
  mutate(data_channel = ifelse(data_channel_is_entertainment==1, "Entertainment",
                        ifelse(data_channel_is_bus==1, "Business",
                        ifelse(data_channel_is_socmed==1, "Social Media",
                        ifelse(data_channel_is_tech==1, "Tech",
                        ifelse(data_channel_is_world==1, "World",
                        ifelse(data_channel_is_lifestyle==1, "Lifestyle", "Other")))))))





qplot(data=data_s,
      factor(weekday),
      log(shares),
      position="jitter")
#number of articles per section
qplot(data=data_s,
      data_channel,
      geom="histogram")

                        
sum(data_s$weekday_flag)              
sum(data_s$weekday)
```

2. Differences in days of the week
``` {r weekdays}


# NEED TO t.test for weekday vs. weekend


qplot(data=data_s, x=factor(weekday), y=shares)
qplot(data=data_s, factor(weekday), log(shares), position="jitter")

# check box plot to see if we can use ANOVA --- WTF IS THIS?
qplot(data=data_s, factor(weekday), shares, geom="boxplot") + coord_flip() + scale_y_discrete(breaks=0:2000)

# To adjust for exponential scale, we took the logarthmic value of the # of shares
qplot(data=data_s, factor(weekday), log(shares), geom="boxplot") + coord_flip()

# It's clear that variances are fairly similar each day, implying it is okay to use ANOVA. At first glance, the means appear to be similar (bearing in mind that we've taken the log), but we will verify with an ANOVA test

# H0 is that there are no differences in the number of shares in any given day
# Ha is that there ARE differences in the number of shares in any given day

summary(aov(data_s$shares ~ data_s$weekday))

# The p-value is 0.314, so with 95% confidence we can accept that there are no statistically significant differences in number of shares between the days of the week.




```


``` {r channels}
3. 

qplot(data=data_s, factor(data_channel), shares)
qplot(data=data_s, factor(data_channel), log(shares), position="jitter")

# check box plot to see if we can use ANOVA
qplot(data=data_s, factor(data_channel), shares, geom="boxplot") + coord_flip()

# To adjust for exponential scale, we took the logarthmic value of the # of shares
qplot(data=data_s, factor(data_channel), log(shares), geom="boxplot") + coord_flip()

# COMMENT ABOUT POSSIBLE DIFFERENCES IN VARIANCES

# H0 is that there are no differences in the number of shares between data_channels (topics)
# Ha is that there ARE differences in the number of shares between data_channels (topics)

summary(aov(data_s$shares ~ data_s$data_channel))

# The p-value is <2e-16, so with 95% confidence we can accept that there are no statistically significant differences in number of shares between the days of the week.


# REDO ANOVA WITHOUT DATA_CHANNEL=OTHER WHICH HAS THE LARGEST VARIANCE

noOther <- data_s %>%
  select(shares, data_channel) %>%
  filter(data_channel!="Other")

count(noOther)/count(data_s)

qplot(data=noOther, factor(data_channel), log(shares), geom="boxplot") + coord_flip()
# now they look good enough

summary(aov(noOther$shares ~ noOther$data_channel))

# anova still has p-value < alpha ---->>>>>>> statistically significant. Reject H0


# NEXT FIND THE BEST TOPIC FOR SHARING / OR / RANK THE TOPICS


# calculates the means for each category

data_s %>%
  select(shares, data_channel) %>%
  group_by(data_channel) %>%
  summarise(mean(shares,na.rm = TRUE ))


```

Question: Which article was shared the most?
```{r}
#Article with the highest number of shares
data_s$url[which.max(data_s$shares)]
<<<<<<< HEAD
max(data_s$shares)
```

Question: Mean shares per group
```{r}
anova(data_s$data_channel, data_s$shares)
```

3. Categories & weekdays
```{r}
summary(aov(data_s$shares ~ data_s$weekday))
qplot(data=data_s,
      factor(weekday),
      log(shares),
      position="jitter")

summary(aov(data_s$shares ~ data_s$data_channel))
qplot(data=data_s,
      factor(data_channel),
      log(shares),
      position="jitter")




summary(data_s$shares)


```

Regression Analysis:
Images
```{r images}
#Videos to shares
qplot(data=data_s[data_s$data_channel=="World",],
      num_imgs,
      shares,
      xlim=c(0, 25),
      ylim=c(0,5000),
      colour=data_channel,
      xlab="Number of videos",
      ylab="Number of Shares",
      main="Relationship between Shares and videos") +
  geom_smooth(method="lm", se=FALSE)
cor(data_s[data_s$data_channel=="World",]$shares, data_s$num_imgs)
lm


#Images

#Internal Href Links

#keywords in title

#token length (wordcount)

cor(data_s$weekday, data_s$shares)


#Days and cat into factors

```


```{r summary echo=TRUE}
summary(data_s)
qplot(data=data,
      shares,
      )
```

