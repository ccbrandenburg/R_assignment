---
title: "R Assignment"
output: html_document
---

Outline (to be deleted following completion):

I. Introduction to project
II. Data cleaning
III. Data Exploration
A. Channels
B. Weekdays
C. Sentiment
IV. Regressions
V. Conclusion

#Summary
#- results
#- techniques used
#- what was missing/failed
#- conclusion (lessons learned)



I. INTRODUCTION

The purpose of this project was to explore a data set using R techniques learned during the course, particularly from the dplyr and ggplot2 libraries. The data set we selected contains information on nearly 40,000 articles published by Mashable over a 2-year period, detailing the day of publication, number of shares, topic of the content and keyword information. Our goal was to identify a meaningful relationship between the articles and their reach (as measured in shares), with the help of the below libraries.

Loading required libraries
```{r library}
library(ggplot2)
library(dplyr)
library(GGally)
library(car)
library(gridExtra)
```

II. DATA CLEANING

The initial data set, downloaded from the University of California Irvine Machine Learning Repository (http://archive.ics.uci.edu/ml/datasets/Online+News+Popularity), had 39644 observations and 61 variables.

Loading and examining the data
```{r load data and examine}
data=read.csv("OnlineNewsPopularity.csv", stringsAsFactors = FALSE)
dim(data)
glimpse(data)
tbl_df(data)
head(data)
tail(data)
summary(data)

#PCA
log.data = log

# Set the seed to make results reproducible
set.seed(27)
data.subset <- data[, c(2:15)]
ggpairs(data.subset[sample.int(nrow(data.subset), 1000), ])
```

We selected only those columns that we believed had a higher probability of correlating positively with increased shares. Our decisions were based on the explanations provided for each variable, the descriptive and summary information calculated and the ggpairs plot. The variables we removed either had unclear descriptions, were deemed redundant given other variables provided, or were not interesting enough to pursue in our analysis.

Our final variables, listed below, included type of content (images, links, videos), length of content (word count in title or article body), day of week published, topic of article, subjectivity and sentiment analysis information. 

```{r variable-reduction}
data_s = data %>%
  select(url,
         timedelta,
         n_tokens_title,
         n_tokens_content,
  # removed variables 4-6
         num_hrefs,
         num_self_hrefs,
         num_imgs,
         num_videos,
         average_token_length,
         num_keywords,
         data_channel_is_lifestyle,
         data_channel_is_entertainment,
         data_channel_is_bus,
         data_channel_is_socmed,
         data_channel_is_tech,
         data_channel_is_world,
  # removed variables 19-30
         weekday_is_monday, 
         weekday_is_tuesday, 
         weekday_is_wednesday,
         weekday_is_thursday, 
         weekday_is_friday,
         weekday_is_saturday,
         weekday_is_sunday,
         is_weekend,
  # removed variables 39-43
         global_subjectivity,
         global_sentiment_polarity,
         global_rate_positive_words,
         global_rate_negative_words,
         rate_positive_words,
         rate_negative_words,
  # removed variables 50-55
         title_subjectivity,
         title_sentiment_polarity,
         abs_title_subjectivity,
         abs_title_sentiment_polarity,
         shares)
```

To make the data easier to manage, we consolidated several similar flag variables into one categorical variable. For example, instead of a categorical variable citing which day of the week the article was published, the original data set had a flag variable for each day of the week stating whether or not the article had been published that day. This was also the case for data_channel, which describes the topic of the article.

There already existed a flag variable called "is_weekend" that marks articles that were published on the weekend. We wanted to explore this, but the definition of weekend was not included. Rather than assume this meant Saturday and Sunday, we created our own flag variable called weekday, which represented any articles published Monday through Friday.

```{r mutating-variables}
data_s = data_s %>%
  #create weekday variable 
  mutate(weekday = ifelse(weekday_is_monday==1, 1,
                    ifelse(weekday_is_tuesday==1, 2,
                    ifelse(weekday_is_wednesday==1, 3,
                    ifelse(weekday_is_thursday==1, 4,
                    ifelse(weekday_is_friday==1, 5,
                    ifelse(weekday_is_saturday==1, 6,
                    ifelse(weekday_is_sunday==1, 7,0)))))))) %>%
  mutate(weekday_flag = ifelse(weekday<=5, 1, 0)) %>%
  #create channel variable
  mutate(data_channel = ifelse(data_channel_is_entertainment==1, "Entertainment",
                        ifelse(data_channel_is_bus==1, "Business",
                        ifelse(data_channel_is_socmed==1, "Social Media",
                        ifelse(data_channel_is_tech==1, "Tech",
                        ifelse(data_channel_is_world==1, "World",
                        ifelse(data_channel_is_lifestyle==1, "Lifestyle", "Other")))))))
```

III. DATA EXPLORATION

Our exploration of the data was split into three main areas of focus: Channels (topic of articles), Weekdays (day of publication), and Sentiment Analysis (positive-vs-negative). For each, we summarized and visualized the variables and plotted against shares.

A. CHANNEL ANALYSIS

The data_channel variable is categorical with 7 levels: Entertainment, Business, Social Media, Tech, World, Lifestyle and Other.
A summary of the data_channel categories provided a good place to start.

Basic statistical overview of shares per channel:
```{r cat overview}
category_overview= data_s %>%
  group_by(data_channel) %>%
  summarise(avg_shares=mean(shares, na.rm = TRUE), 
            median_shares=median(shares),
            max_shares=max(shares),
            min_shares=min(shares),
            sd_shares=sd(shares),
            article_count=length(shares))
category_overview
```

The following pieces of information stood out to us:
1. There are far fewer articles about Lifestyle (2099) or Social Media (2323) than the other 5 categories, each of which had between 6134 (Other) and 8427 (World)
2. Max shares is much larger for Business (690400), Tech (663600) and Other (843300) than the others (between 122800 and 284700)
3. Median shares varies among categories more so than the other summary statistics, with a high of 2100 (Social Media) a d low of 1100 (World) and the other 5 spread between the two extremes.
4. The Other category has a much higher average number of shares (5945) than any other category (between 2287 and 3682)
5. The Other (19393) and Business (15046) categories have much higher standard deviation of shares than the others (between 5524 and 9024)

To explore these observations, we took to plotting the channel data, adding complexity with each progressive graph.

The following section tries to provide a visual overview of how shares are distributed across channels.
```{r channel plot1}
p1 <- ggplot(data_s , aes(factor(data_channel), shares)) + geom_jitter()
p1
```

This initial plot is extremely difficult to read, so we made a few adjustments to scale and colors, focusing on the majority of the data points and adding lines representing the mean (blue) and median (red) number of shares.

```{r channel plot2}
p2 <- ggplot(data = data_s, 
        aes(x=factor(data_channel), 
            y = shares, 
            group = as.integer(data_channel))) +
  geom_jitter(alpha=0.15)+
  coord_cartesian(,c(0,50000)) + 
    geom_line(stat= "summary" ,
              fun.y = mean, color=I("blue")) + 
    geom_line(stat= "summary" ,
              fun.y = median, color=I("red")) 
p2 
```

These changes helped, but it is clear that the graph would be more easily interpreted if we use a logarithmic scale instead of simply adjusting the y-limits.

```{r channel plot3}
p3 <- ggplot(data = data_s, 
        aes(x=factor(data_channel), 
            y = log(shares), 
            group = as.integer(data_channel))) +
  geom_jitter(alpha=0.15)+
    geom_line(stat= "summary" ,
              fun.y = mean, color=I("blue")) + 
    geom_line(stat= "summary" ,
              fun.y = median, color=I("red")) 
p3
```

The logarithmic version is much more helpful, as we can now see some of the observations represented in the summary. For example, we can see that Lifestyle and Social Media have fewer articles (#1), max shares is larger for Business, Tech and Other (#2), and the differences in Median and Mean (#3-4) across articles. The Other category clearly stands out as different, in part because of its larger variance (#5).

Before running an ANOVA test, we compared boxplots of the data to compare the variance and see if ANOVA would be a valid method to use.

```{r channel plot4}
p4 <- qplot(data=data_s, 
      factor(data_channel), 
      shares, 
      geom="boxplot") + 
  coord_flip()
p4
```

Without a log scale, the box plots were useless, but with log scale, we can clearly see the ranges, medians and interquartile widths of each category.

``` {r channel plot5}
p5 <- qplot(data=data_s, 
      factor(data_channel), 
      log(shares),
      geom="boxplot") + 
  coord_flip()
p5
```

The width of the Other category box is clearly larger, but before accounting for this difference in variances, we will establish our ANOVA hypotheses and run an initial test. We want to know with 95% confidence if there is a statistically significant difference in how many shares an article receives, depending on its data_channel. Our hypotheses are as follows:

H0: There are no differences in the average number of shares for articles of different data_channels
Ha: There ARE differences in the average number of shares for articles of different data_channels. At least two data_channels have statistically significant differences in average shares.

```{r anova channels}
summary(aov(data_s$shares ~ data_s$data_channel))
```

Including all categories, the p-value is <2e-16, so with 95% confidence we can accept that there are at least two data_channels with a statistically significant difference in average number of shares. Because of the suspicious variance in the Other category, and the fact that Other is not a well-defined category, we redid the test removing Other articles.

To start, we filtered the data_s data set for all categories not equal to Other and confirmed this still represented a large portion of the data.

```{r channels is not equal other}
noOther <- data_s %>%
  select(shares, data_channel) %>%
  filter(data_channel!="Other")

#verify the filter works
count(noOther)/count(data_s)
```

85% of the data remained, so we repeated the box plots with the new noOther data set.

Create a new boxplot
```{r channel plot 6}
p6 <- qplot(data=noOther, 
      factor(data_channel), 
      log(shares), 
      geom="boxplot") + 
  coord_flip()
p6
```

This looks much better, with more similar variances.

```{r anova channels not other}
summary(aov(noOther$shares ~ noOther$data_channel))
```
ANOVA still has p-value < alpha which is statistically significant. We therefore reject the null hypothesis that there are no differences in the average number of shares for articles of different data_channels. We are confident we can include this in our regression model.


B. WEEKDAY ANALYSIS

The weekday variable is categorical with 7 levels, each representing a day of the week. Once again, we started with a basic summary of the data.

Basic statistical overview of shares per weekday:
```{r weekday overview}
weekday_overview = data_s %>%
  group_by(weekday) %>%
  summarise(avg_shares=mean(shares, na.rm = TRUE), 
            median_shares=median(shares),
            max_shares=max(shares),
            min_shares=min(shares),
            sd_shares=sd(shares),
            article_count=length(shares))
weekday_overview
```

The following pieces of information stood out to us:
1. There were far fewer articles published on Saturday (2453) and Sunday (2737) than the rest of the week, each of which had between 5701 (Friday) and 7435 (Wednesday)
2. Max shares is much noticeably low for Sunday (83300) and much larger for Wednesday (843300) and Monday (690400) compared to the other days (between 233400 and 441000)
3. Median shares is much larger on Saturday (2000) and Sunday (1900) than the other days (between 1300 and 1500)
4. Likewise, average shares per is higher for Saturday (4078) and Sunday (3746) than all the others, except for Monday (3647). All other days have between 3178 and 3303.
5. Lastly, standard deviation is much lower on Sunday (6214) than Monday (14691), Wednesday (14588) and Saturday (14230). The other days have standard deviation between 8148 and 9798.

We found it interesting that Saturday and Sunday had far fewer articles than the rest of the days, but higher median and average shares per article. Yet, standard deviation for Sunday was less than half that of Saturday.

Keeping in mind the benefits of plotting against shares using a logarithmic scale, we set out to find patterns in the pubication days.

Plotting how number of shares are distributed across weekdays.
```{r weekday plot1}
q1 <- ggplot(data = data_s, 
        aes(x=factor(weekday), 
            y = log(shares), 
            group = as.integer(weekday))) +
      geom_jitter(alpha=0.15) + 
      labs(x="Weekday", y="Log of Shares", title="Article shares per Weekday")
q1 
```



Creating box plots per weekday to see if we can use ANOVA
```{r weekday plot2}
# check box plot to see if we can use ANOVA
qplot(data=data_s, 
      factor(weekday), 
      shares,
      geom="boxplot") + 
  coord_flip()

# To adjust for exponential scale, we took the logarthmic value of the # of shares
qplot(data=data_s, 
      factor(weekday), 
      log(shares), 
      geom="boxplot") + 
  coord_flip()
```
It's clear that variances are fairly similar each day, implying it is okay to use ANOVA. At first glance, the means appear to be similar (bearing in mind that we've taken the log), but we will verify with an ANOVA test.

H0: there are no differences in the number of shares in any given day
Ha: there ARE differences in the number of shares in any given day

```{r weekday anova}
summary(aov(data_s$shares ~ data_s$weekday))
```
The p-value is 0.314, so we do not reject H0 that there are no statistically significant differences in number of shares between the days of the week.

Judging by the table above saturday and sundays seem to have higher means. There might be a difference in shares between weekends and weekdays? 1=Weekday, 0=Weekend

```{r weekday vs weekends}
weekend_overview= data_s %>%
  group_by(weekday_flag) %>%
  summarise(avg_shares=mean(shares, na.rm = TRUE), 
            median_shares=median(shares),
            max_shares=max(shares),
            min_shares=min(shares),
            sd_shares=sd(shares),
            article_count=length(shares))
weekend_overview
```

Coming up with a new hypothesis.
H0: there are no differences in the number of shares on weekdays vs weekends
Ha: there ARE differences in the number of shares on weekdays vs weekends.
```{r weekday plot3}
qplot(data=data_s,
      factor(weekday_flag),
      log(shares), 
      geom="boxplot") + 
  coord_flip()
```
Visually there does not seem to be significant difference. And check what ANOVA can tell us. (can we use ANOVA here for testing differences between only two groups or should be default to t-test?????)

```{r anova weekday flag}
summary(aov(data_s$shares ~ data_s$weekday_flag))
```
The p-value is 0.000734 and less than the significance level of 5% so we do reject H0 and have statistically significant evidence that the number of shares differ between weekdays and weekends.

Question: Which article was shared the most?
```{r}
#Article with the highest number of shares
data_s$url[which.max(data_s$shares)]
max(data_s$shares)
```

Question: Mean shares per group
```{r}
summary(aov(data_s$shares ~ data_s$data_channel))
```
The p-value is 0.000734 and less than the significance level of 5% so we do reject H0 and have statistically significant evidence that the number of shares differ between weekdays and weekends.


5. OTHER ANALYSES

The following graphs are used to understand whether there are visual differences between how positive and negative words affect the number of shares. From the graphs and the correlations there does not seem to be a relationship.

```{r negative vs positive words}
qpos = qplot(data=data_s,
      rate_positive_words,
      shares,
      log="xy") +
  geom_point(alpha=1/200)

qneg = qplot(data=data_s,
      rate_negative_words,
      shares,
      log="xy") +
  geom_point(alpha=1/200)

grid.arrange(qpos, qneg, nrow=1)

cor(data_s$rate_positive_words, data_s$shares)

cor(data_s$rate_negative_words, data_s$shares)
```



6. Regression Analysis:
```{r messing around}
summary(data_s)

#plotting images
ggplot(aes(y=shares, x=num_imgs), data=data_s) + 
  geom_point(alpha=1/20) +
  ylim(0, quantile(data_s$shares, probs=0.95)) +
  geom_smooth(method="lm", color="red")
```

REGRESSION ANALYSIS
We will first create a new dataset to work with
```{r regression data}
data_R = data_s %>%
  select(url,
         num_keywords,
         n_tokens_title,
         num_imgs,
         num_videos,
         n_tokens_content, 
         rate_positive_words,
         rate_negative_words,
         title_sentiment_polarity,
         title_subjectivity,
         title_sentiment_polarity,
         abs_title_subjectivity,
         abs_title_sentiment_polarity,
         average_token_length,
         shares,
         weekday)
```
Checking correlations between the variables and shares.
```{r cor check}
cor(data_R [,unlist(lapply(data_R, is.numeric))])
```
It becomes clear that the variables individually do not have a big impact on the amount of shares of articles. We will therefore check different models and see whether we can find a relationship between different variables in combination and shares.

```{r r sub}
sub <- lm(data= data_R, abs_title_sentiment_polarity ~ title_sentiment_polarity + title_subjectivity + abs_title_subjectivity) 
summary(sub)
```

```{r r sub1}
sub1 <- lm(data= data_R, abs_title_sentiment_polarity ~ (title_sentiment_polarity + title_subjectivity + abs_title_subjectivity)^ 2)
summary(sub1)
```

```{r r sub 1 comparison}
anova(sub,sub1)
```
sub1 is so far the more superior model.

We will now introduce interaction between variables
```{r r sub2}
sub2 <- lm(data= data_R, abs_title_sentiment_polarity ~ title_sentiment_polarity + (title_subjectivity + abs_title_subjectivity)^2)
summary(sub2)
```

```{r r sub3}
sub3 <- lm(data= data_R, abs_title_sentiment_polarity ~ (title_sentiment_polarity + title_subjectivity)^2 + abs_title_subjectivity)
summary(sub3)
```

```{r r sub4}
sub4 <- lm(data= data_R, abs_title_sentiment_polarity ~ title_subjectivity + (title_sentiment_polarity + abs_title_subjectivity)^2)
summary(sub4)
```

Introducing polynomial regression models
```{r r sub5}
sub5 <- lm(data= data_R, abs_title_sentiment_polarity ~ ( I(title_sentiment_polarity^2) + I(title_subjectivity^2) + I(abs_title_subjectivity^2)))
summary(sub5)
```
Checking which whether sub5 is better than the previous models.
```{r anova sub 5}
anova(sub1,sub5)
```
So far sub5 seems to be the best model.

Making further adjustments to the model
```{r r sub6}
sub6 <-  lm(data= data_R, abs_title_sentiment_polarity ~ ( I(title_sentiment_polarity^2) + (title_subjectivity) + (abs_title_subjectivity)))
summary(sub6)
```

Comparing sub5 and sub6
```{r anova 5 and 6}
anova(sub5,sub6)
```
We prefer sub6 as this model has less complexity.


```{r r sub7}
sub7 <- lm(data= data_R, abs_title_sentiment_polarity ~ I(title_sentiment_polarity^2)) 
summary(sub7)
```

Comparing sub6 and sub7
```{r anova 6 and 7}
anova(sub6,sub7)
```
ANOVA tells us to go for sub6 since it has significantly the highest R^2


Checking Linearity
```{r linearity}
qplot( predict(sub6), 
       resid(sub6),
       geom= "point") + 
  geom_hline(yintercept = 0)
```
There clearly seems to be a problem since there is a very clear pattern in the residuals.

Checking Normality
```{r normality}
q1= qplot(rstandard(sub6), 
          geom="blank") + 
  geom_histogram(aes(y=..density..), 
                 colour=I("gray")) +
  stat_function(fun=dnorm, 
                args=list(mean=0,sd=1), 
                colour=I("red"), 
                alpha=I(0.5))

q2 = qplot(sample=rstandard(sub6)) + 
  geom_abline(slope=1, 
              intercept = 0)

#arranging graphs in grid
grid.arrange(q1,q2,nrow=1)
```
The graphs seem to imply that we cannot go out of a normal distribution of the residuals.

Checking Homoscedasticity
```{r homoscedasticity}
qplot(predict(sub6),
      resid(sub6), 
      geom= "point") + 
  geom_hline(y_intercept = 0)

spreadLevelPlot(sub6)
```
This doens't look like the homoscedasticity condition can be hold, the line should normally be horizontal and we can see a clear change of variance in the residuals along the x-axis. 

Checking Independence
```{r independence}
durbinWatsonTest(sub6)
```
This test seems to be ok as the null-hypothesis of independence cannot be rejected.

Checking Multicollinearity
```{r multicol}
vif(sub6)
```
This test shows no Multicollinearity, since all vifs are clearly smaller than 5.

Checking Outliers
```{r outliers}
outlierTest(sub6)
```



